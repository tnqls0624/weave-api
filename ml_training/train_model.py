"""
SMS í”¼ì‹± íƒì§€ LSTM ëª¨ë¸ í•™ìŠµ
TensorFlow/Keras ê¸°ë°˜
"""

import os
import json
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# ì„¤ì •
MAX_WORDS = 10000  # ì–´íœ˜ í¬ê¸°
MAX_SEQUENCE_LENGTH = 200  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
EMBEDDING_DIM = 128  # ì„ë² ë”© ì°¨ì›
LSTM_UNITS_1 = 64
LSTM_UNITS_2 = 32
DENSE_UNITS = 16
DROPOUT_RATE = 0.3
BATCH_SIZE = 32
EPOCHS = 20
VALIDATION_SPLIT = 0.2

class PhishingModelTrainer:
    def __init__(self):
        self.tokenizer = None
        self.model = None
        self.history = None

    def load_data(self, csv_path="phishing_dataset.csv"):
        """ë°ì´í„° ë¡œë“œ"""
        print("=" * 60)
        print("ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("=" * 60)

        df = pd.read_csv(csv_path, encoding='utf-8-sig')

        print(f"\nì´ ë°ì´í„° ìˆ˜: {len(df)}")
        print(f"í”¼ì‹±: {df['is_phishing'].sum()}")
        print(f"ì •ìƒ: {len(df) - df['is_phishing'].sum()}")

        # ë©”ì‹œì§€ì™€ ë¼ë²¨ ì¶”ì¶œ
        messages = df['message'].values
        labels = df['is_phishing'].values

        return messages, labels

    def preprocess_text(self, messages, labels):
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° í† í°í™”"""
        print("\n" + "=" * 60)
        print("í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘...")
        print("=" * 60)

        # Tokenizer ì´ˆê¸°í™”
        self.tokenizer = Tokenizer(
            num_words=MAX_WORDS,
            oov_token="<OOV>",
            filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n'
        )

        # í† í°í™”
        self.tokenizer.fit_on_texts(messages)

        # ì‹œí€€ìŠ¤ ë³€í™˜
        sequences = self.tokenizer.texts_to_sequences(messages)

        # íŒ¨ë”©
        padded_sequences = pad_sequences(
            sequences,
            maxlen=MAX_SEQUENCE_LENGTH,
            padding='post',
            truncating='post'
        )

        print(f"\nì–´íœ˜ í¬ê¸°: {len(self.tokenizer.word_index)}")
        print(f"ì‹œí€€ìŠ¤ ê¸¸ì´: {MAX_SEQUENCE_LENGTH}")
        print(f"ìƒ˜í”Œ ì‹œí€€ìŠ¤ í˜•íƒœ: {padded_sequences.shape}")

        # Train/Test ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            padded_sequences,
            labels,
            test_size=0.2,
            random_state=42,
            stratify=labels
        )

        print(f"\ní•™ìŠµ ë°ì´í„°: {len(X_train)}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}")

        return X_train, X_test, y_train, y_test

    def build_model(self):
        """LSTM ëª¨ë¸ êµ¬ì¶•"""
        print("\n" + "=" * 60)
        print("ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        print("=" * 60)

        model = keras.Sequential([
            # ì„ë² ë”© ë ˆì´ì–´
            layers.Embedding(
                input_dim=MAX_WORDS,
                output_dim=EMBEDDING_DIM,
                input_length=MAX_SEQUENCE_LENGTH,
                name='embedding'
            ),

            # ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´
            layers.Bidirectional(
                layers.LSTM(
                    LSTM_UNITS_1,
                    return_sequences=True,
                    dropout=DROPOUT_RATE,
                    recurrent_dropout=0.2
                ),
                name='bi_lstm_1'
            ),

            # ë‘ ë²ˆì§¸ LSTM ë ˆì´ì–´
            layers.Bidirectional(
                layers.LSTM(
                    LSTM_UNITS_2,
                    dropout=DROPOUT_RATE,
                    recurrent_dropout=0.2
                ),
                name='bi_lstm_2'
            ),

            # Dense ë ˆì´ì–´
            layers.Dense(DENSE_UNITS, activation='relu', name='dense'),
            layers.Dropout(DROPOUT_RATE, name='dropout'),

            # ì¶œë ¥ ë ˆì´ì–´
            layers.Dense(1, activation='sigmoid', name='output')
        ])

        # ëª¨ë¸ ì»´íŒŒì¼
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]
        )

        self.model = model

        # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
        print("\nëª¨ë¸ êµ¬ì¡°:")
        model.summary()

        return model

    def train(self, X_train, y_train, X_test, y_test):
        """ëª¨ë¸ í•™ìŠµ"""
        print("\n" + "=" * 60)
        print("ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        print("=" * 60)

        # ì½œë°± ì„¤ì •
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=3,
                restore_best_weights=True,
                verbose=1
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=2,
                verbose=1,
                min_lr=0.00001
            ),
            keras.callbacks.ModelCheckpoint(
                'best_model.h5',
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            )
        ]

        # í•™ìŠµ
        self.history = self.model.fit(
            X_train,
            y_train,
            batch_size=BATCH_SIZE,
            epochs=EPOCHS,
            validation_split=VALIDATION_SPLIT,
            callbacks=callbacks,
            verbose=1
        )

        # í…ŒìŠ¤íŠ¸ í‰ê°€
        print("\n" + "=" * 60)
        print("í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€...")
        print("=" * 60)

        test_loss, test_accuracy, test_precision, test_recall = self.model.evaluate(
            X_test,
            y_test,
            verbose=1
        )

        print(f"\ní…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}")
        print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
        print(f"í…ŒìŠ¤íŠ¸ ì •ë°€ë„: {test_precision:.4f}")
        print(f"í…ŒìŠ¤íŠ¸ ì¬í˜„ìœ¨: {test_recall:.4f}")
        print(f"F1 Score: {2 * (test_precision * test_recall) / (test_precision + test_recall):.4f}")

        return self.history

    def evaluate_detailed(self, X_test, y_test):
        """ìƒì„¸ í‰ê°€"""
        print("\n" + "=" * 60)
        print("ìƒì„¸ í‰ê°€...")
        print("=" * 60)

        # ì˜ˆì¸¡
        y_pred_proba = self.model.predict(X_test)
        y_pred = (y_pred_proba > 0.5).astype(int)

        # ë¶„ë¥˜ ë¦¬í¬íŠ¸
        print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
        print(classification_report(
            y_test,
            y_pred,
            target_names=['ì •ìƒ', 'í”¼ì‹±']
        ))

        # í˜¼ë™ í–‰ë ¬
        print("\ní˜¼ë™ í–‰ë ¬:")
        cm = confusion_matrix(y_test, y_pred)
        print(cm)
        print(f"\nTrue Negatives: {cm[0][0]}")
        print(f"False Positives: {cm[0][1]}")
        print(f"False Negatives: {cm[1][0]}")
        print(f"True Positives: {cm[1][1]}")

        # ì •í™•ë„ ê³„ì‚°
        accuracy = (cm[0][0] + cm[1][1]) / cm.sum()
        precision = cm[1][1] / (cm[1][1] + cm[0][1])
        recall = cm[1][1] / (cm[1][1] + cm[1][0])
        f1 = 2 * (precision * recall) / (precision + recall)

        print(f"\nìµœì¢… ë©”íŠ¸ë¦­:")
        print(f"ì •í™•ë„: {accuracy:.4f}")
        print(f"ì •ë°€ë„: {precision:.4f}")
        print(f"ì¬í˜„ìœ¨: {recall:.4f}")
        print(f"F1 Score: {f1:.4f}")

    def plot_history(self):
        """í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™”"""
        print("\ní•™ìŠµ íˆìŠ¤í† ë¦¬ í”Œë¡¯ ìƒì„± ì¤‘...")

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # ì†ì‹¤
        axes[0, 0].plot(self.history.history['loss'], label='Train Loss')
        axes[0, 0].plot(self.history.history['val_loss'], label='Val Loss')
        axes[0, 0].set_title('Model Loss')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)

        # ì •í™•ë„
        axes[0, 1].plot(self.history.history['accuracy'], label='Train Accuracy')
        axes[0, 1].plot(self.history.history['val_accuracy'], label='Val Accuracy')
        axes[0, 1].set_title('Model Accuracy')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True)

        # ì •ë°€ë„
        axes[1, 0].plot(self.history.history['precision'], label='Train Precision')
        axes[1, 0].plot(self.history.history['val_precision'], label='Val Precision')
        axes[1, 0].set_title('Model Precision')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Precision')
        axes[1, 0].legend()
        axes[1, 0].grid(True)

        # ì¬í˜„ìœ¨
        axes[1, 1].plot(self.history.history['recall'], label='Train Recall')
        axes[1, 1].plot(self.history.history['val_recall'], label='Val Recall')
        axes[1, 1].set_title('Model Recall')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Recall')
        axes[1, 1].legend()
        axes[1, 1].grid(True)

        plt.tight_layout()
        plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
        print("í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥: training_history.png")

    def save_model(self, output_dir="../models/phishing_detection_model"):
        """ëª¨ë¸ SavedModel í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        print("\n" + "=" * 60)
        print("ëª¨ë¸ ì €ì¥ ì¤‘...")
        print("=" * 60)

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)

        # SavedModel í˜•ì‹ìœ¼ë¡œ ì €ì¥ (Keras 3 - export ì‚¬ìš©)
        self.model.export(output_dir)
        print(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_dir}")

        # ì–´íœ˜ ì‚¬ì „ ì €ì¥
        vocab_path = os.path.join(output_dir, "vocabulary.json")
        with open(vocab_path, 'w', encoding='utf-8') as f:
            json.dump(self.tokenizer.word_index, f, ensure_ascii=False, indent=2)
        print(f"ì–´íœ˜ ì‚¬ì „ ì €ì¥: {vocab_path}")

        # ì„¤ì • ì €ì¥
        config = {
            "max_words": MAX_WORDS,
            "max_sequence_length": MAX_SEQUENCE_LENGTH,
            "embedding_dim": EMBEDDING_DIM,
            "vocab_size": len(self.tokenizer.word_index)
        }
        config_path = os.path.join(output_dir, "config.json")
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2)
        print(f"ì„¤ì • ì €ì¥: {config_path}")

    def test_predictions(self, test_messages):
        """í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡"""
        print("\n" + "=" * 60)
        print("í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡...")
        print("=" * 60)

        for message in test_messages:
            # ì „ì²˜ë¦¬
            sequence = self.tokenizer.texts_to_sequences([message])
            padded = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')

            # ì˜ˆì¸¡
            prediction = self.model.predict(padded, verbose=0)[0][0]

            print(f"\në©”ì‹œì§€: {message}")
            print(f"í”¼ì‹± í™•ë¥ : {prediction:.4f}")
            print(f"íŒì •: {'ğŸš¨ í”¼ì‹±' if prediction > 0.5 else 'âœ… ì •ìƒ'}")

def main():
    print("=" * 60)
    print("SMS í”¼ì‹± íƒì§€ ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)

    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = PhishingModelTrainer()

    # 1. ë°ì´í„° ë¡œë“œ
    messages, labels = trainer.load_data("phishing_dataset.csv")

    # 2. ì „ì²˜ë¦¬
    X_train, X_test, y_train, y_test = trainer.preprocess_text(messages, labels)

    # 3. ëª¨ë¸ êµ¬ì¶•
    trainer.build_model()

    # 4. í•™ìŠµ
    trainer.train(X_train, y_train, X_test, y_test)

    # 5. ìƒì„¸ í‰ê°€
    trainer.evaluate_detailed(X_test, y_test)

    # 6. íˆìŠ¤í† ë¦¬ í”Œë¡¯
    trainer.plot_history()

    # 7. ëª¨ë¸ ì €ì¥
    trainer.save_model()

    # 8. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    test_messages = [
        "ê¸´ê¸‰! êµ­ë¯¼ì€í–‰ ê³„ì¢Œê°€ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. http://bit.ly/abc123ì—ì„œ í™•ì¸í•˜ì„¸ìš”.",
        "ë‚´ì¼ íšŒì˜ ì¼ì • í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
        "[êµ­ì„¸ì²­] í™˜ê¸‰ê¸ˆ 500,000ì›ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. http://me2.do/xyzì—ì„œ ê³„ì¢Œ ì…ë ¥í•˜ì„¸ìš”.",
        "ì˜¤ëŠ˜ ì €ë… ì•½ì† ì–´ë•Œìš”?",
        "ì¶•í•˜í•©ë‹ˆë‹¤! ì´ë²¤íŠ¸ ë‹¹ì²¨ 1,000,000ì› ìƒí’ˆê¶Œ. http://short.link/abc",
    ]
    trainer.test_predictions(test_messages)

    print("\n" + "=" * 60)
    print("í•™ìŠµ ì™„ë£Œ!")
    print("=" * 60)
    print("\nëª¨ë¸ íŒŒì¼ ìœ„ì¹˜: ../models/phishing_detection_model/")
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("1. application.ymlì—ì„œ phishing.model.enabled=trueë¡œ ë³€ê²½")
    print("2. ì„œë²„ ì¬ì‹œì‘")

if __name__ == "__main__":
    main()
